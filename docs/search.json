[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nBeyond the Worst-Case Analysis\n\n\n\n\n\n\nalgorithms\n\n\nresearch\n\n\n\n\n\n\n\n\n\nJun 18, 2025\n\n\nClaire To\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Algorithm Analysis\n\n\n\n\n\n\nalgorithms\n\n\nteaching\n\n\n\n\n\n\n\n\n\nJun 16, 2025\n\n\nClaire To\n\n\n\n\n\n\n\n\n\n\n\n\nStaying Long Enough to Belong\n\n\n\n\n\n\nreflections\n\n\n\n\n\n\n\n\n\nMay 2, 2025\n\n\nClaire To\n\n\n\n\n\n\n\n\n\n\n\n\nNature, Nurture, and the Space Between\n\n\n\n\n\n\nreflections\n\n\n\n\n\n\n\n\n\nApr 13, 2025\n\n\nClaire To\n\n\n\n\n\n\n\n\n\n\n\n\nGraduate Application Essay\n\n\n\n\n\n\nreflections\n\n\n\n\n\n\n\n\n\nDec 15, 2024\n\n\nClaire To\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/alg-analysis/index.html",
    "href": "posts/alg-analysis/index.html",
    "title": "Understanding Algorithm Analysis",
    "section": "",
    "text": "I’ve noticed that a lot of students – whether they’re currently taking algorithms or have already completed the course – often confuse cases with bounds when discussing algorithm analysis. I know I personally have had to wrestle with this concept myself for quite a while.\nMy hope is that this helps clear up some of that confusion and provides an intuitive, tangible overview of these concepts. It’s not meant to be a comprehensive or formal discussion, as there are already countless resources online, but rather a more approachable supplement for those who already have some background."
  },
  {
    "objectID": "posts/alg-analysis/index.html#case-analysis",
    "href": "posts/alg-analysis/index.html#case-analysis",
    "title": "Understanding Algorithm Analysis",
    "section": "Case Analysis",
    "text": "Case Analysis\nWhen analyzing how long an algorithm takes, we consider how it behaves in different cases, depending on the input.\n\nBest Case\nThe shortest possible time an algorithm takes on any input.\nFor example, when searching for a number in a list, the best case could be finding it at the first index. In insertion sort, the best case is when the array is already sorted.\nThis is less useful in practice, since it’s too optimistic and best case scenarios are unlikely to happen.\n\n\nWorst Case\nThe longest possible time an algorithm takes on any input.\nFor example, the worst case in searching for a number in a list is when the number is found at the very last position checked or not found in the list at all. In insertion sort, the worst case occurs when the array is reverse-sorted.\nThis is the most pessimistic, but also a reliable way to measure an algorithm’s performance because it guarantees that the algorithm will always run within a certain time.\n\n\nAverage Case\nThe expected runtime over all inputs, assuming a certain input distribution.\nThat means we average the running times of the algorithm over all possible inputs, weighted by their probability.\n\nProbability Distributions\n\nUniform distribution: Models all input where each instance is equally likely. Most common in average-case analysis of general algorithms.\nBernoulli distribution: Useful when inputs are sequences of binary events (success/failure). Most common in probabilistic or randomized algorithms.\nGeometric distribution: Models the number of trials until the first success. Most common in probabilistic or randomized algorithms."
  },
  {
    "objectID": "posts/alg-analysis/index.html#asymptotic-bounds",
    "href": "posts/alg-analysis/index.html#asymptotic-bounds",
    "title": "Understanding Algorithm Analysis",
    "section": "Asymptotic Bounds",
    "text": "Asymptotic Bounds\nIn algorithm analysis, we often use asymptotic bounds to describe how an algorithm’s running time grows as the input grows larger.\nYou can visualize this by plotting the runtime for increasing input sizes and comparing it to well-known functions like \\(n\\), \\(n \\log n\\), or \\(n^2\\). This is the core idea behind asymptotic comparison of growth rates.\n\nUpper Bound\nAn upper bound usually describes the maximum amount of work a specific algorithm requires to solve a problem.\nAn upper bound for a problem is established by providing an algorithm that achieves that bound. Thus, an algorithm’s upper bound also provides an upper bound for the problem it solves.\nUpper bounds are often proven using:\n\nDirect algorithm analysis\nRecurrence relations\nAmortized analysis\n\n\n\nLower Bound\nWhen discussing lower bounds, it’s important to distinguish between a bound on a specific algorithm and a bound on the inherent difficulty of a problem.\n\nFor a Specific Algorithm\nA lower bound for an algorithm indicates the minimum amount of work that specific algorithm requires to solve a problem in a given case, usually in the worst case.\nLower bounds for algorithms are often proven using:\n\nDirect algorithm analysis\n\n\n\nFor a Problem\nA lower bound for a problem indicates the minimum amount of work any correct algorithm requires to solve a problem, always in the worst case.\nThis is a much stronger statement about the fundamental, inherent difficulty of the problem itself. Lower bound proofs for problems establish the theoretical best performance achievable under a defined model of computation.\nFor example, searching for an element in an unsorted list requires \\(n\\) comparisions because we must check every element. Otherwise, we might miss the one we didn’t check, and that could’ve been the correct one.\nLower bounds for problems are often proven using:\n\nCounting arguments\n\nDecision trees\n\nAdversary arguments\n\nInformation theory\nReductions (P ?= NP)"
  },
  {
    "objectID": "posts/alg-analysis/index.html#asymptotic-notation",
    "href": "posts/alg-analysis/index.html#asymptotic-notation",
    "title": "Understanding Algorithm Analysis",
    "section": "Asymptotic Notation",
    "text": "Asymptotic Notation\nIn theoretical computer science, unless specified otherwise, asymptotic notation usually refers to the worst case. In practice, especially with randomized algorithms or heuristics, expected or average case complexity may be more relevant.\n\nBig O: \\(O(f(n))\\)\nAn upper bound that shows the algorithm \\(A\\)’s running time grows no faster than some function \\(f(n)\\) as the input size grows.\nThe function \\(f(n)\\)’s graph is asymptotically above or equal to algorithm \\(A\\)’s graph.\n\n\nBig Omega: \\(\\Omega(f(n))\\)\nA lower bound that shows the algorithm \\(A\\)’s running time grows no slower than some function \\(f(n)\\) as the input size grows.\nThe function \\(f(n)\\)’s graph is asymptotically below or equal to algorithm \\(A\\)’s graph.\n\n\nTheta: \\(\\Theta(f(n))\\)\nThis indicates a tight bound. In other words, for a specific algorithm, its upper and lower bounds are equivalent up to constant factors. This gives us a very precise understanding of how that algorithm’s runtime grows.\nThe function \\(f(n)\\)’s graph is asymptotically equivalent to algorithm \\(A\\)’s graph.\nSolving recurrance relations, such as by using the Master Theorem, gives us a tight bound on that algorithm’s performance.\nAn algorithm is considered asymptotically optimal for a problem when it has a tight bound that matches the problem’s proven lower bound, meaning we have found the fastest possible algorithm for that problem. If an algorithm’s worst-case upper bound matches the lower bound of the problem it solves, then it is implied that the algorithm has a tight bound.\n\n\nLittle o: \\(o(f(n))\\)\nSimilar to Big O, but shows the algorithm \\(A\\)’s running time is strictly slower than \\(f(n)\\).\nThe function \\(f(n)\\)’s graph is asymptotically above algorithm \\(A\\)’s graph.\nFor example, \\(n\\) grows strictly slower than \\(n \\log n\\).\n\n\nLittle omega: \\(\\omega(f(n))\\)\nSimilar to Big Omega, but shows the algorithm \\(A\\)’s running time is strictly faster than \\(f(n)\\).\nThe function \\(f(n)\\)’s graph is asymptotically below algorithm \\(A\\)’s graph.\nFor example, \\(n \\log n\\) grows strictly faster than \\(n\\).\n\nRemember, cases describe an algorithm’s performance on specific types of input, while asymptotic bounds and its notation describe its growth rate relative to increasing input size. I hope this helps clear up some common misconceptions!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Claire A. To",
    "section": "",
    "text": "Hello! I’m a PhD student in Computer Science at the University of California, Irvine in the Center for Algorithms and Theory of Computation. I’m honored to be advised by Dr. Michael Goodrich.\nContact: claire [dot] to [at] uci [dot] edu"
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Claire A. To",
    "section": "",
    "text": "Hello! I’m a PhD student in Computer Science at the University of California, Irvine in the Center for Algorithms and Theory of Computation. I’m honored to be advised by Dr. Michael Goodrich.\nContact: claire [dot] to [at] uci [dot] edu"
  },
  {
    "objectID": "index.html#research",
    "href": "index.html#research",
    "title": "Claire A. To",
    "section": "Research",
    "text": "Research\nMy research is in Theoretical Computer Science, with a focus on algorithms and data structures for computational geometry. I became interested in research through my work in computer science education, and that experience inspired my pursuit of a PhD. Though my path here was unexpected, I am grateful for the journey that led me to this field."
  },
  {
    "objectID": "index.html#teaching",
    "href": "index.html#teaching",
    "title": "Claire A. To",
    "section": "Teaching",
    "text": "Teaching\nCS 161: Design and Analysis of Algorithms Term(s): Fall 2025"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Claire A. To",
    "section": "Education",
    "text": "Education\nUniversity of California, Irvine\nPh.D in Computer Science | Sept 2025 - Present\nOrange Coast College\nA.A in Dance | Aug 2024 - Present\nUniversity of California, Irvine\nB.S in Computer Science | Sept 2023 - Jun 2025\nOrange Coast College\nA.A in Liberal Arts | Aug 2021 - May 2023\nOrange Coast College\nA.S in Computer Science | Aug 2020 - May 2023\nHuntington Beach High School\nHigh School Diploma | Aug 2017 - May 2021"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Entropy-Bounded Computational Geometry Made Easier and Sensitive to Sortedness\nDavid Eppstein, Michael T. Goodrich, Abraham M. Illickan, Claire A. To\nThe 37th Canadian Conference on Computational Geometry (CCCG 2025)\nWe study instance optimality–algorithms that achieve the performance of the best correct algorithm on every input, with respect to a measure. By leveraging input structure and sortedness, we design simple algorithms for classic computational geometry problems, including maxima set, convex hull, and visibility, and prove new bounds under a complexity measure sensitive to both properties.\nPaper | Poster | Slides (Complete)\n\n\n\nInvestigating the Capabilities of Generative AI in Solving Data Structures, Algorithms, and Computability Problems\nNero Li, Shahar Broner, Yubin Kim, Katrina Mizuo, Elijah Sauder, Claire To, Albert Wang, Ofek Gila, Michael Shindler\nThe 56th Technical Symposium on Computer Science Education (SIGCSE TS 2025)\nOur study evaluates the ability of generative AI models to solve advanced problems in data structures, algorithms, and computability. By testing 165 free-response questions across 16 theoretical computer science topics, we analyze the strengths and limitations of these models, highlighting their potential for education and automated tutoring.\nPaper | Slides\n\n\n\nCommon Strategy Patterns of Persuasion in a Mission Critical and Time Sensitive Task\nClaire To, Setareh Nasihati Gilani, David Traum\nThe 27th Workshop on the Semantics and Pragmatics of Dialogue (SemDial 2023 - MariLogue)\nOur research examines persuasion strategies in high-stakes, time-sensitive disaster relief interactions, analyzing how dialogue structure, speech acts, and urgency impact outcomes. By identifying patterns in communication, we explore how situational factors influence decision-making and persuasion effectiveness in crisis scenarios.\nPaper | Poster | Slides"
  },
  {
    "objectID": "posts/beyond-worst/index.html",
    "href": "posts/beyond-worst/index.html",
    "title": "Beyond the Worst-Case Analysis",
    "section": "",
    "text": "Worst-case analysis measures an algorithm by its performance on the hardest, adversarial input, often yielding an overly pessimistic result. This brings to light the discussion of beyond worst-case analysis: a more fine-grained approach that allows us to more accurately measure an algorithm’s performance.\nMy first theory research project, which I was fortunate to be part of during my undergrad, was inspired by the paper “Instance-Optimal Geometric Algorithms” by Peyman Afshani, Jérémy Barbay, and Timothy Chan. Here, I’ll briefly provide an overview of some of the core concepts."
  },
  {
    "objectID": "posts/beyond-worst/index.html#adaptive-analysis",
    "href": "posts/beyond-worst/index.html#adaptive-analysis",
    "title": "Beyond the Worst-Case Analysis",
    "section": "Adaptive Analysis",
    "text": "Adaptive Analysis\nAdaptive analysis measures an algorithm’s execution cost not only as a function of input size, but also with respect to other parameters that can more precisely capture the input’s inherent difficulty (e.g., output size).\nFor example, in computational geometry, there are well-known output-sensitive algorithms to compute 2D and 3D convex hulls in \\(O(n \\text{ log } h)\\), where \\(h\\) is the output size (i.e., the number of points on the hull). The fewer points there are on the hull, the faster the algorithm will run."
  },
  {
    "objectID": "posts/beyond-worst/index.html#instance-optimality",
    "href": "posts/beyond-worst/index.html#instance-optimality",
    "title": "Beyond the Worst-Case Analysis",
    "section": "Instance Optimality",
    "text": "Instance Optimality\nInstance optimality represents the ultimate form of adaptive analysis. An algorithm is instance-optimal if its cost is within a constant factor of the best possible algorithm’s cost on that exact same input.\nFor example, the 2D convex hull problem has a worst-case complexity of \\(\\Theta (n \\text{ log } n)\\) in the algebraic computation tree model (a common model for analyzing geometric algorithms where only comparisons and basic arithmetic are allowed), but algorithms exist that can solve this problem on certain input instances (e.g. sorted points) in \\(O(n)\\) time. An instance-optimal algorithm would need to match this runtime.\nLikewise, to sort a list of numbers, a list that is already sorted should run faster could be “sorted” in \\(O(n)\\) time. We only need to check if the list is already sorted then we can return it without any additional operations. In the comparison-based model (where algorithms use only element comparisons), an instance-optimal sorting algorithm would need to achieve \\(O(n)\\) time on already-sorted input if there exists some comparison-based algorithm that does so.\nGiven the strictness of this definition, the paper introduces two variants of instance optimality: order-oblivious and random-order settings.\nThese variations allow us to show instance optimality against a strong benchmark even when a universally ultimate optimal algorithm is a theoretical ideal that is unknown or unproven. In my project, we worked on improving upon and proving algorithms in the order-oblivious setting.\n\nOrder-Oblivious Setting\nAn algorithm \\(A\\) is considered instance-optimal in the order-oblivious setting if, for any given input set of elements, its worst-case runtime (across all possible permutations of that input) is within a constant factor of the best possible worst-case runtime achieved by any algorithm \\(A'\\) from the class \\(C\\) of all correct algorithms.\nBecause this compares the performance of algorithms \\(A\\) and \\(A’\\) on their own worst permutation (which may not be the same between them), this analysis ensures that the algorithm’s performance guarantee holds regardless of how the input elements are initially ordered. In other words, the analysis conceptually shuffles the input to find the hardest scenario for a given algorithm and input set, even if the algorithm itself does not randomize the input.\nThis implies that such an algorithm is also optimal output-sensitive and optimal adaptive with respect to any parameters that are independent of the input’s order (e.g., data spread, expected size, or relative positions of points).\n\n\nRandom-Order Setting\nAn algorithm \\(A\\) is considered instance-optimal in the random-order setting if, for any given input set of elements, its average runtime (across all possible permutations of that input) is within a constant factor of the best possible average runtime achieved by any algorithm \\(A'\\) from the class \\(C\\) of all correct algorithms.\nThe analysis implicitly creates a uniform probability distribution over all permutations of the input set and then calculates the algorithm’s average performance under this distribution.\nTherefore, this is a stronger definition than order-oblivious instance optimality because the average runtime across all permutations of that set will never be worse than the worst runtime across all permutations of that same input set. By averaging over all possible input permutations, this setting captures the algorithm’s expected performance, preventing the influence of either best-case or worst-case input ordering.\nThis setting is particularly relevant for analyzing algorithms that incorporate randomness. Algorithms that are instance-optimal in the random-order setting are competitive against randomized or randomized incremental algorithms (where input elements are randomly permuted as a preprocessing step) and traditional average-case optimality (which assumes an input probability distribution).\n\nIn this dynamic field of algorithm analysis, adaptive and instance-optimal analysis are only two out of the many powerful approaches. To delve deeper, Tim Roughgarden’s “Beyond the Worst-Case Analysis of Algorithms” course and textbook covers a number of modeling methods and frameworks for going beyond worst-case analysis. Ultimately, the goal of these techniques is to bridge the gap between theoretical guarantees and real-world performance."
  },
  {
    "objectID": "photos.html",
    "href": "photos.html",
    "title": "Photos",
    "section": "",
    "text": "SIGCSE 2025\n\n\n\n\n\n\n\nCCCG 2025\n\n\n\n\n\n\n\n\n\nWADS/CCCG 2025"
  },
  {
    "objectID": "posts/nature-nurture/index.html",
    "href": "posts/nature-nurture/index.html",
    "title": "Nature, Nurture, and the Space Between",
    "section": "",
    "text": "I had a discussion with my family about nature vs. nurture — a deeply personal debate that reflects how we perceive our potential and how much we’re willing to endure to reach it.\nMy family believes that there is a personal limit to everything, and that no amount of training or effort can push you beyond a level you don’t innately possess. I agree with them to an extent when it comes to physical traits. Some physical attributes are essential for professional athletes, and many can’t attain them no matter how much they train. Even then, I’ve heard many stories where people have defied what should’ve been possible for them. On the other hand, when it comes to mental abilities, the situation feels more nuanced.\nI believe in neuroplasticity which is the ability of our brain to adapt and evolve. Skills such as public speaking, for example, seem to be one that can be learned and refined with enough training. I believe such skills don’t have a hard limit.\nMaybe it’s overly optimistic, but when it comes to abilities such as intelligence, I think there’s more to it. I know that not everyone can be an Einstein, but I do think that most people never come close to reaching their true potential. Too often, people assume their limits are far lower than they actually are, and give up far too early when things begin to feel difficult. But it’s during these moments of struggle that we experience the most growth and emerge stronger on the other side.\nFrom my experience in academia, it’s hard not to feel this way especially when I’m surrounded by some of the most intelligent people. There are moments when I feel like I don’t belong, that I’m not cut out for this. As a result, I’ve nearly held myself back time and time again.\nI was trapped my own self-doubt. I couldn’t escape the perspective I had built around something I hadn’t yet experienced and knew so little about from the outside. I simply believed that only those born with a certain level of intelligence could accomplish it and that I was nowhere near qualified.\nIt wasn’t until I met someone at the right moment who unknowingly changed my life that made me see everything in a different light. They once told me:\n“I just wanted you to not worry too much about holding yourself back, because I don’t think you should be the one holding yourself back. Let the world do that. Let the world tell you you’re not good enough and then ignore it.”\nThose words felt so empowering. It brought me a newfound feeling of hope and courage into my life. It made me realize how often I’d given up before the world ever had the chance to stop me.\nIn my moments of doubt, my parents were supportive of me stepping away. They didn’t see the value in pushing further when the challenges felt like too much of a struggle. They often praised how far I’d come, but at the same time, they would say they couldn’t have done it themselves.\nI don’t think that’s true.\nI never felt like I possessed innate talent in this field of study. Nothing has ever come easy to me; I had to work and struggle for every single piece of it. That’s exactly why I believe anyone can do it with enough stubbornness and perseverance.\nIn my times of uncertainty and doubt, it was those who had already been ahead of me and had gone through the same challenges that encouraged me to keep going. From community college to my bachelor’s degree and now pursuing a PhD, at each pivotal phase in my life, those who haven’t experienced the journey themselves feared it and questioned whether I could do it, while those who had walked the path believed it was possible.\nIf not for the people I met along the way, I may not be where I am today. Maybe I wouldn’t even believe in the possibility of reaching my limits.\nI think it’s a tragedy that so many people give up the moment things get tough, and never discover how far they can really go. Like standing at the bottom of a mountain — you don’t know if you’ll make it over, but if you do, you might discover something you never imagined on the other side, and everything in between.\nSo why not try? Try until you fail, and only then will you discover your true limit."
  },
  {
    "objectID": "posts/staying/staying.html",
    "href": "posts/staying/staying.html",
    "title": "Staying Long Enough to Belong",
    "section": "",
    "text": "I’ve come to realize that in every part of my life — dance, academics, and friendships — I’ve had to start from nothing. Yet, despite the challenges, I decided to try my best anyway."
  },
  {
    "objectID": "posts/staying/staying.html#dance",
    "href": "posts/staying/staying.html#dance",
    "title": "Staying Long Enough to Belong",
    "section": "Dance",
    "text": "Dance\nI often mention how I was forbidden to dance growing up. My parents discouraged it after my cousin majored in dance and struggled with her career. Still, I was always drawn to it through Just Dance, YouTube, and shows like Dance Moms. But I wasn’t allowed to try it myself until college. Maybe if I had gone to school in a more Asian-dominated area, it would’ve felt different, but in middle and high school, I never felt like I belonged there.\nI started with nothing. I had no background in gymnastics or flexibility, and I could barely touch my toes. I didn’t even grow up listening to music. So when I started learning K-pop, I had no rhythm, no sense of sound. I danced by watching movements and matching them to lyrics, not by feeling the beat. But practicing through K-pop gave me enough confidence to step into real dance classes from hip-hop to modern. I especially loved modern dance because the movement felt freeing and expansive, even if I still lacked flexibility and couldn’t hear the music.\nOne style that always captivated me was contemporary. I would watch the dance department showcases and be in awe. It looked so fast, difficult, expressive, and deeply technical. I couldn’t imagine ever being good enough to take that class. For two years, I admired from afar.\nBut after graduating from community college, I felt this pull to try again. That summer, I trained to build the strength and flexibility I thought I’d need. I worked until I could achieve the splits and touch my toes with ease. When I finally enrolled in the contemporary class, I expected to struggle, but to my surprise, I kept up easily. In fact, I physically exceeded many of the dancers who had been dancing since they were kids.\nThat was a strange feeling. Everyone around me had ~20 years of dance under their belt. I had maybe two years. And yet, while my lack of technique showed, especially in musicality and turns, I could keep up. In some areas, I even excelled. My teacher often commented on the contrast: how I could be so flexible and controlled with so little background, and yet also so clearly new to dance in other ways. It’s like there are huge gaps in my ability, some natural strengths, and some deep holes.\nI’m still improving. Month by month, I’m starting to hear the music more, and my turns are slowly getting better. The progress is slow, but I can feel it happening."
  },
  {
    "objectID": "posts/staying/staying.html#computer-science",
    "href": "posts/staying/staying.html#computer-science",
    "title": "Staying Long Enough to Belong",
    "section": "Computer Science",
    "text": "Computer Science\nWith computer science, I’ve had more struggles than I can count. I didn’t understand pointers, and many concepts made me feel like I was drowning. At one point, I unofficially dropped out of the major, and it was the people around me who gave me the courage to try again. I made it through and transferred, but that wasn’t the end of the story. When I transferred, I realized I was severely behind, especially in algorithm design. I was missing prerequisite knowledge in data structures and algorithms, yet I was expected to keep up with students who had the proper background. That quarter nearly broke me. I was overwhelmed and stressed, not just because the content was hard, but because I felt like I was letting down a professor who genuinely believed in me.\nIt didn’t end there either. The next quarter was somehow worse. The week we implemented Zip-Zip trees was the lowest point of my life. The structure was inspired by two data structures: Skip Lists, which I had never encountered, and balanced binary search trees, neither of which I had never implemented. We were expected to code it in Python, a language I had never been properly taught. All of these were prerequisites UCI students had, but I was missing. It wasn’t the only struggle that quarter, but it was the one that hit me the hardest.\nSomehow, I’m still here. Still struggling, but learning to be proud because I made it through. I’m now pursuing a PhD in algorithms, the very subject I find the most difficult. I took introductory algorithms less than a year before applying. Some days I wonder how I got here, why I was accepted, whether I belong at all. My lab-mates say it’s normal to feel that way, but they all had years of theory experience. I had none. Not only that, but I struggled in all my theory classes. They had a years of mathematical maturity, while I barely scraped by with limited math and dismissed classes like discrete math and statistics, thinking I’d never need them, only to now find that they’re the core language of my work.\nI sit in theory talks and often don’t understand. Maybe I’ve trained myself to sit in confusion long enough to stay. Sometimes I tell people how lost I am, and some say it’s okay, while others look concerned. I’ve come to notice that those who have experienced more struggle and made it through tend to insist that I will be okay. I hope the people who do believe in me are right because I have placed my trust in them.\nI’ve always looked up to the theory students. I can’t help but value intelligence and knowledge, and to me, they embodied both. I placed them on a pedestal: intimidating and inspiring. Sometimes I would peek into the lab through the window and see scribbles on the whiteboard. It felt like a different world, one I could never understand. It wasn’t imposter syndrome, at least not at first. Even before I ever considered pursuing theory, I was afraid of that lab. It carried a different air from the others. I never imagined I could be one of them. But somehow, that same lab has become my home, not because I suddenly understand everything, but because I stayed long enough to belong.\nI’m not sure when that shift happened. Maybe it was the environments I was encouraged into, the people I met along the way, and my willingness to stay even when I felt like I didn’t belong. They say your environment shapes who you become, and maybe by putting myself in those rooms, I slowly and unintentionally rewrote my own path without realizing it. One moment later, I look around and realize I’m in the very room, among the very people, that once felt worlds away. And that makes me think maybe that’s what growth is. Not a dramatic transformation, but staying long enough in the discomfort until it starts to feel normal like home.\nStarting theory research has made me cry. I felt so overwhelmed and terrified of disappointing my advisor and worried that he would give up on me. There were days I’d reread a single paragraph over and over, unable to make sense of it, but I still kept showing up and trying. Slowly, painfully but slowly, I’m staring to feel the slightest bit of progress. I can follow research meetings better. My lab-mate’s explanations are a bit clearer, when not too long ago, I couldn’t comprehend much of what he said. I can read and dissect a proof without immediately feeling overwhelmed. It’s still difficult, but I’m starting to see small pieces click into place.\nI don’t know how fast I’m supposed to be progressing. I don’t know what’s expected of me. But I hope that my effort will eventually be enough."
  },
  {
    "objectID": "posts/staying/staying.html#friendships",
    "href": "posts/staying/staying.html#friendships",
    "title": "Staying Long Enough to Belong",
    "section": "Friendships",
    "text": "Friendships\nAs for friends, I’ve had to rebuild my social circle from scratch. It forced me to take initiative and present myself as the person I wished I was. I was never that social girl, or the popular one, or the confident one, the one unafraid to speak up. I wanted to be her, but the gap between who I was and who I wanted to be felt so vast that it almost felt like acting. I was playing a role to be likable, someone accepted.\nOver time, I started to become that person. Not by pretending, but by slowly stepping into it until it felt natural. Now, I’m someone who can be warm and outgoing when needed, while still keeping my core beliefs and values unshakable and true to myself. Having had to start over before, I now trust that I’ll be okay wherever I go because I know how to rebuild from nothing.\nMaybe all of these experiences are why I am who I am today. I don’t know what the future holds or if everything will crash and burn one day. But I want to believe that all this struggle wasn’t for nothing. That everything I’ve learned — the pain, the persistence, the growth — will lead to some kind of success, whatever that ends up meaning for me. I’ve rebuilt before. I’ve started from the beginning in so many areas of my life: physically, intellectually, socially. And I think, no matter what happens, I’ll be able to do it again if I need to."
  },
  {
    "objectID": "teaching/cs161/cs161.html",
    "href": "teaching/cs161/cs161.html",
    "title": "CS 161 Resources",
    "section": "",
    "text": "Algorithm Analysis\n\nBlog post\n\n\n\nMaster Theorem\n\nLecture slides"
  },
  {
    "objectID": "teaching/cs161/cs161.html#master-theorem",
    "href": "teaching/cs161/cs161.html#master-theorem",
    "title": "CS 161 Course Materials",
    "section": "",
    "text": "Lecture slides"
  }
]